{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Input, Dense, concatenate\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
        "\n",
        "tf.random.set_seed(3407)  # Replace 42 with your desired seed number\n",
        "np.random.seed(3407)  # Numpy seed\n",
        "random.seed(3407)     # Python's built-in random module"
      ],
      "metadata": {
        "id": "C-iq5FqWJv8K"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert an array of values into a dataset matrix\n",
        "def create_dataset(dataset, look_back=1):\n",
        "  dataX, dataY = [], []\n",
        "  for i in range(len(dataset)-look_back-1):\n",
        "    a = dataset[i:(i+look_back)]\n",
        "    dataX.append(a)\n",
        "    dataY.append(dataset[i + look_back])\n",
        "  return np.array(dataX), np.array(dataY)\n",
        "\n",
        "def fill_nan(arr):\n",
        "    # Forward fill\n",
        "    mask = np.isnan(arr)\n",
        "    idx = np.where(~mask, np.arange(mask.shape[0]), 0)\n",
        "    np.maximum.accumulate(idx, axis=0, out=idx)\n",
        "    out = arr[idx]\n",
        "\n",
        "    # Backward fill for the remaining NaNs\n",
        "    mask = np.isnan(out)\n",
        "    idx = np.where(~mask, np.arange(mask.shape[0]), mask.shape[0] - 1)\n",
        "    idx = np.minimum.accumulate(idx[::-1], axis=0)[::-1]\n",
        "    out = out[idx]\n",
        "\n",
        "    return out\n",
        "\n",
        "# split into train and test sets\n",
        "def split_dataset(array):\n",
        "  train_size = int(len(array) * 0.67)\n",
        "  test_size = len(array) - train_size\n",
        "  train, test = array[:train_size], array[train_size:len(array)]\n",
        "  return train, test\n",
        "\n",
        "# load the dataset\n",
        "dataframe = pd.read_csv('data_daily.csv', usecols=[1], engine='python')\n",
        "\n",
        "dataset = dataframe.astype('float32')\n",
        "dataset = dataset.values\n",
        "dataset = dataset/1e5\n",
        "\n",
        "# Decompose the time series\n",
        "decomposition = sm.tsa.seasonal_decompose(dataset, model='additive', period = 12)  # or model='multiplicative' based on your data\n",
        "\n",
        "# Extract the trend, seasonality, and residuals\n",
        "trend = decomposition.trend\n",
        "seasonal = decomposition.seasonal\n",
        "residual = decomposition.resid\n",
        "\n",
        "trend = fill_nan(trend)\n",
        "seasonal = fill_nan(seasonal)\n",
        "residual = fill_nan(residual)\n",
        "\n",
        "trend = trend.reshape(-1,1)\n",
        "seasonal = seasonal.reshape(-1,1)\n",
        "residual = residual.reshape(-1,1)"
      ],
      "metadata": {
        "id": "Jt7-eklE0X-B"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defined look back period (days)\n",
        "look_back = 90\n",
        "\n",
        "# Define inputs for each aspect\n",
        "input_dataset = Input(shape=(look_back,))\n",
        "input_residuals = Input(shape=(look_back,))\n",
        "input_trend = Input(shape=(look_back,))\n",
        "input_seasonal = Input(shape=(look_back,))\n",
        "\n",
        "# Subnetwork for dataset\n",
        "net_dataset = Dense(12, activation='relu', kernel_initializer=tf.keras.initializers.GlorotUniform(seed=42))(input_dataset)\n",
        "net_dataset = Dense(8, activation='swish', kernel_initializer=tf.keras.initializers.GlorotUniform(seed=42))(net_dataset)\n",
        "\n",
        "# Subnetwork for residuals\n",
        "net_residuals = Dense(12, activation='tanh', kernel_initializer=tf.keras.initializers.GlorotUniform(seed=42))(input_residuals)\n",
        "net_residuals = Dense(8, activation='tanh', kernel_initializer=tf.keras.initializers.GlorotUniform(seed=42))(net_residuals)\n",
        "net_residuals = Dense(8, activation='tanh', kernel_initializer=tf.keras.initializers.GlorotUniform(seed=42))(net_residuals)\n",
        "\n",
        "# Subnetwork for trend\n",
        "net_trend = Dense(12, activation='relu', kernel_initializer=tf.keras.initializers.GlorotUniform(seed=42))(input_trend)\n",
        "net_trend = Dense(8, activation='swish', kernel_initializer=tf.keras.initializers.GlorotUniform(seed=42))(net_trend)\n",
        "\n",
        "# Subnetwork for seasonal\n",
        "net_seasonal = Dense(12, activation='relu', kernel_initializer=tf.keras.initializers.GlorotUniform(seed=42))(input_seasonal)\n",
        "net_seasonal = Dense(8, activation='tanh', kernel_initializer=tf.keras.initializers.GlorotUniform(seed=42))(net_seasonal)\n",
        "net_seasonal = Dense(8, activation='tanh', kernel_initializer=tf.keras.initializers.GlorotUniform(seed=42))(net_seasonal)\n",
        "\n",
        "# Combine all subnetworks\n",
        "combined = concatenate([net_dataset, net_residuals, net_trend, net_seasonal])\n",
        "\n",
        "# Separate output layers for each prediction target\n",
        "output_dataset = Dense(1, name='output_dataset')(combined)\n",
        "output_residuals = Dense(1, name='output_residuals')(combined)\n",
        "output_trend = Dense(1, name='output_trend')(combined)\n",
        "output_seasonal = Dense(1, name='output_seasonal')(combined)\n",
        "\n",
        "# Create multi-output model\n",
        "model = Model(inputs=[input_dataset, input_residuals, input_trend, input_seasonal],\n",
        "              outputs=[output_dataset, output_residuals, output_trend, output_seasonal])\n",
        "model.compile(optimizer='adam',\n",
        "              loss={'output_dataset': 'mean_squared_error',\n",
        "                    'output_residuals': 'mean_squared_error',\n",
        "                    'output_trend': 'mean_squared_error',\n",
        "                    'output_seasonal': 'mean_squared_error'},\n",
        "              metrics={'output_dataset': 'mae',\n",
        "                       'output_residuals': 'mae',\n",
        "                       'output_trend': 'mae',\n",
        "                       'output_seasonal': 'mae'})"
      ],
      "metadata": {
        "id": "4d4KjnzKZB4D"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data for each aspect\n",
        "trainX_dataset, trainY_dataset = create_dataset(dataset, look_back)\n",
        "trainX_residuals, trainY_residuals = create_dataset(residual, look_back)\n",
        "trainX_trend, trainY_trend = create_dataset(trend, look_back)\n",
        "trainX_seasonal, trainY_seasonal = create_dataset(seasonal, look_back)\n",
        "\n",
        "model.fit([trainX_dataset, trainX_residuals, trainX_trend, trainX_seasonal],\n",
        "          {'output_dataset': trainY_dataset,\n",
        "           'output_residuals': trainY_residuals,\n",
        "           'output_trend': trainY_trend,\n",
        "           'output_seasonal': trainY_seasonal},\n",
        "          epochs=10, batch_size=32, verbose=2, shuffle = False)"
      ],
      "metadata": {
        "id": "zdUl7tKeBaaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the last 'look_back' values from each aspect\n",
        "last_values_dataset = dataset[-look_back:].reshape(1, look_back)\n",
        "last_values_residuals = residual[-look_back:].reshape(1, look_back)\n",
        "last_values_trend = trend[-look_back:].reshape(1, look_back)\n",
        "last_values_seasonal = seasonal[-look_back:].reshape(1, look_back)\n",
        "\n",
        "num_future_steps = 365  # Number of future steps to forecast\n",
        "\n",
        "# Create empty lists to store the forecasted values for each aspect\n",
        "forecasted_dataset = []\n",
        "forecasted_residuals = []\n",
        "forecasted_trend = []\n",
        "forecasted_seasonal = []\n",
        "\n",
        "for _ in range(num_future_steps):\n",
        "    # Predict the next set of values\n",
        "    predictions = model.predict([last_values_dataset, last_values_residuals, last_values_trend, last_values_seasonal])\n",
        "    predicted_dataset, predicted_residuals, predicted_trend, predicted_seasonal = predictions\n",
        "\n",
        "    # Append the predicted values to the forecast lists\n",
        "    forecasted_dataset.append(predicted_dataset[0, 0])\n",
        "    forecasted_residuals.append(predicted_residuals[0, 0])\n",
        "    forecasted_trend.append(predicted_trend[0, 0])\n",
        "    forecasted_seasonal.append(predicted_seasonal[0, 0])\n",
        "\n",
        "    # Update the last_values arrays with the newly predicted values\n",
        "    # For each aspect, we roll the array to remove the first (oldest) value and append the new prediction\n",
        "    last_values_dataset = np.roll(last_values_dataset, -1)\n",
        "    last_values_dataset[0, -1] = predicted_dataset\n",
        "\n",
        "    last_values_residuals = np.roll(last_values_residuals, -1)\n",
        "    last_values_residuals[0, -1] = predicted_residuals\n",
        "\n",
        "    last_values_trend = np.roll(last_values_trend, -1)\n",
        "    last_values_trend[0, -1] = predicted_trend\n",
        "\n",
        "    last_values_seasonal = np.roll(last_values_seasonal, -1)\n",
        "    last_values_seasonal[0, -1] = predicted_seasonal\n",
        "\n",
        "# Convert the forecast lists to numpy arrays\n",
        "forecasted_dataset = np.array(forecasted_dataset).reshape(-1, 1)\n",
        "forecasted_residuals = np.array(forecasted_residuals).reshape(-1, 1)\n",
        "forecasted_trend = np.array(forecasted_trend).reshape(-1, 1)\n",
        "forecasted_seasonal = np.array(forecasted_seasonal).reshape(-1, 1)"
      ],
      "metadata": {
        "id": "vyqwO7YPDfEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare index for forecast data\n",
        "forecast_start_index = len(dataset)  # Assuming 'dataset' is your original time series data\n",
        "forecast_indices = np.arange(forecast_start_index, forecast_start_index + num_future_steps)\n",
        "\n",
        "# Plot Original Data and Forecasts\n",
        "plt.figure(figsize=(15, 18))\n",
        "\n",
        "# Plot Original Dataset\n",
        "plt.subplot(4, 1, 1)  # 4 rows, 1 column, 1st plot\n",
        "plt.plot(dataset, label='Original Dataset')\n",
        "plt.plot(forecast_indices, forecasted_dataset, label='Forecasted Dataset', color='orange')\n",
        "plt.title('Original Dataset and Forecast')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Dataset Values')\n",
        "plt.legend()\n",
        "\n",
        "# Plot Residuals\n",
        "plt.subplot(4, 1, 2)  # 4 rows, 1 column, 2nd plot\n",
        "plt.plot(residual, label='Original Residuals')  # Assuming 'residual' is your original residuals data\n",
        "plt.plot(forecast_indices, forecasted_residuals, label='Forecasted Residuals', color='red')\n",
        "plt.title('Original Residuals and Forecast')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Residual Values')\n",
        "plt.legend()\n",
        "\n",
        "# Plot Trend\n",
        "plt.subplot(4, 1, 3)  # 4 rows, 1 column, 3rd plot\n",
        "plt.plot(trend, label='Original Trend')  # Assuming 'trend' is your original trend data\n",
        "plt.plot(forecast_indices, forecasted_trend, label='Forecasted Trend', color='green')\n",
        "plt.title('Original Trend and Forecast')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Trend Values')\n",
        "plt.legend()\n",
        "\n",
        "# Plot Seasonal\n",
        "plt.subplot(4, 1, 4)  # 4 rows, 1 column, 4th plot\n",
        "plt.plot(seasonal, label='Original Seasonal')  # Assuming 'seasonal' is your original seasonal data\n",
        "plt.plot(forecast_indices, forecasted_seasonal, label='Forecasted Seasonal', color='blue')\n",
        "plt.title('Original Seasonal and Forecast')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Seasonal Values')\n",
        "plt.legend()\n",
        "\n",
        "# Show the plots\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "U7kLCK-Z2mhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the trend, residuals, and seasonal additively for forecast\n",
        "combined_forecast = forecasted_trend + forecasted_residuals + forecasted_seasonal\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "# Assuming 'original_series' is your original time series data\n",
        "plt.plot(dataset, label='Original Series')\n",
        "\n",
        "# Plotting the combined forecast\n",
        "plt.plot(np.arange(len(dataset), len(dataset) + len(combined_forecast)), combined_forecast, label='Combined Forecast', color='orange')\n",
        "\n",
        "plt.title('Original Time Series and Combined Forecast')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Values')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_IElWoyE7G2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('ty_custom_model.h5')"
      ],
      "metadata": {
        "id": "mPGSsEXzYXRw"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# look_back = 90\n",
        "# trainX_dataset, trainY_dataset = create_dataset(dataset, look_back)\n",
        "\n",
        "# # Input for the dataset aspect\n",
        "# input_dataset = Input(shape=(look_back,))\n",
        "# net_dataset = Dense(12, activation='relu', kernel_initializer=tf.keras.initializers.GlorotUniform(seed=42))(input_dataset)\n",
        "# net_dataset = Dense(8, activation='swish', kernel_initializer=tf.keras.initializers.GlorotUniform(seed=42))(net_dataset)\n",
        "# output_dataset = Dense(1, name='output_dataset')(net_dataset)\n",
        "# model_dataset = Model(inputs=input_dataset, outputs=output_dataset)\n",
        "# model_dataset.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# model_dataset.fit([trainX_dataset], trainY_dataset, epochs=8, batch_size=32, verbose=2, shuffle = False)\n",
        "\n",
        "# # Extract the last 'look_back' values from each aspect\n",
        "# last_values_dataset = dataset[-look_back:].reshape(1, look_back)\n",
        "\n",
        "# num_future_steps = 365  # Number of future steps to forecast\n",
        "# forecasted_values = []\n",
        "\n",
        "# for _ in range(num_future_steps):\n",
        "#     # Predict the next value\n",
        "#     next_step_prediction = model_dataset.predict([last_values_dataset])\n",
        "\n",
        "#     # Append the predicted value\n",
        "#     forecasted_values.append(next_step_prediction[0, 0])\n",
        "\n",
        "#     # Update the main dataset's input for the next prediction\n",
        "#     last_values_dataset = np.roll(last_values_dataset, -1)\n",
        "#     last_values_dataset[0, -1] = next_step_prediction\n",
        "\n",
        "# # Convert forecasted_values to a numpy array\n",
        "# forecasted_values = np.array(forecasted_values).reshape(-1, 1)"
      ],
      "metadata": {
        "id": "bh6E8LJLPfLI"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# import numpy as np\n",
        "\n",
        "# # Plot the original dataset\n",
        "# plt.figure(figsize=(15, 6))\n",
        "# plt.plot(dataset, label='Original Dataset')\n",
        "\n",
        "# # Prepare the forecast data for plotting\n",
        "# # Starting index for forecast data is right after the end of t/he original dataset\n",
        "# forecast_start_index = len(dataset)\n",
        "# # Creating an array for plotting that aligns with the original dataset\n",
        "# forecastPlot = np.empty((forecast_start_index + num_future_steps, 1))\n",
        "# forecastPlot[:, :] = np.nan\n",
        "# # Inserting the forecasted values\n",
        "# forecastPlot[forecast_start_index:forecast_start_index + num_future_steps, :] = forecasted_values\n",
        "\n",
        "# # Plotting the forecast\n",
        "# plt.plot(forecastPlot, label='Forecast (Next 120 days)', color='orange')\n",
        "\n",
        "# # Adding titles and labels\n",
        "# plt.title('Original Dataset and 120-Day Forecast')\n",
        "# plt.xlabel('Time')\n",
        "# plt.ylabel('Values')\n",
        "# plt.legend()\n",
        "\n",
        "# # Show the plot\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "UbFv58S_hm8L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}